{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4652e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "\n",
    "%run focalloss.ipynb\n",
    "%run mfeloss.ipynb\n",
    "%run msfeloss.ipynb\n",
    "\n",
    "class NeuralN(nn.Module):\n",
    "    \"\"\" \n",
    "        Class to represent the autoencoder and reflect the customizable pattern. \n",
    "\n",
    "        Args: \n",
    "            input_dimension (int) : Size of input dimension\n",
    "            output_dimension (int) : Size of output dimension\n",
    "            hidden_layers (list[int]) : List of hidden layers.\n",
    "            num_hidden_layers (int) : Amount of hidden layers.\n",
    "            hidden_dim (int): Default hidden dimension. \n",
    "            activation_default (str): Default activation function.\n",
    "            activations (list[str]) : List of activation functions. \n",
    "            loss_method (str) : Loss method to evaluate training and testing. \n",
    "            opt_method (str): Optimization method. \n",
    "            lr (float): Learning rate. \n",
    "            alpha (float): Parameter for focal loss function.\n",
    "            gamma (float): Parameter for focal loss function.\n",
    "            epochs (int): Number of epochs. \n",
    "            threshold (float): Threshold to make predictions.\n",
    "            class_weights (dict): Class weights for imbalanced sets.\n",
    "            data_type (pytorch object): Data type to avoid confusion.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dimension = None, output_dimension = None, hidden_layers=None, num_hidden_layers = None, hidden_dim = 64,\n",
    "                 activation_default = \"relu\", threshold = 0.3,\n",
    "                 activations = None, loss_method = \"BCE\", opt_method = \"SGD\", lr = 0.01, class_weights = None, alpha=None, data_type = None, gamma = None, epochs=None):\n",
    "        \n",
    "        super().__init__() \n",
    "        \n",
    "        self.loss_method = loss_method\n",
    "        self.opt_method = opt_method\n",
    "        self.lr = lr \n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma \n",
    "        self.epochs = epochs\n",
    "        self.input_dimension = input_dimension \n",
    "        self.output_dimension = output_dimension\n",
    "        self.hidden_layers = hidden_layers #list\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.hidden_dim = hidden_dim #default\n",
    "        self.activation_default = activation_default #default \n",
    "        self.activations = activations #list\n",
    "        self.data_type = data_type\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor([class_weights[1], class_weights[0]], dtype= torch.float32)\n",
    "        else: \n",
    "            self.class_weights = class_weights\n",
    "        \n",
    "        self.process = nn.ModuleList()\n",
    "\n",
    "        layer = None\n",
    "        if self.hidden_layers is not None:\n",
    "            \n",
    "            layer = [self.input_dimension] + self.hidden_layers + [self.output_dimension]\n",
    "\n",
    "        else: \n",
    "\n",
    "            layer = [self.input_dimension] + [self.hidden_dim]*self.num_hidden_layers + [self.output_dimension]\n",
    "\n",
    "        act = None\n",
    "        if self.activations is not None:\n",
    "            \n",
    "            if len(self.activations) < (len(layer)):\n",
    "                need = (len(layer)) - len(self.activations)\n",
    "                act = self.activations + [\"identity\"]*need \n",
    "            \n",
    "            else: \n",
    "                act = self.activations\n",
    "\n",
    "        else: \n",
    "\n",
    "            act = [self.activation_default]* (len(layer) - 1) \n",
    "\n",
    "        for i in range(1, len(layer)):\n",
    "            self.process.append(nn.Linear(layer[i-1], layer[i]))\n",
    "            \n",
    "            if i < (len(layer) - 1):\n",
    "                self.process.append(self.get_activation(act[i-1]))\n",
    "            \n",
    "            elif i == (len(layer) - 1):\n",
    "\n",
    "                if self.loss_method == \"BCE\": \n",
    "                    self.process.append(nn.Sigmoid())\n",
    "\n",
    "                else: \n",
    "                    self.process.append(nn.Identity())\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" \n",
    "        Forward method to initate the transformation of the input to output.\n",
    "        \n",
    "            Parameters: \n",
    "                x (tensor) : Training tensor for x. \n",
    "        \n",
    "            Returns: \n",
    "                Returns the processed version of the input.\n",
    "        \"\"\"\n",
    "        x = x.float()\n",
    "        for m in self.process:\n",
    "            x = m(x)\n",
    "        return x\n",
    "\n",
    "    def get_activation(self, activation_):\n",
    "        \"\"\" \n",
    "            Method to select the activation function.\n",
    "\n",
    "            Parameters: \n",
    "                activation_ (str): Name of the activation function as a string.\n",
    "\n",
    "            Returns: \n",
    "                Returns the activation function with nn module. \n",
    "\n",
    "        \"\"\"\n",
    "        if activation_ == \"relu\": \n",
    "            return nn.ReLU()\n",
    "\n",
    "        elif activation_ == \"tanh\": \n",
    "            return nn.Tanh()\n",
    "\n",
    "        elif activation_ == \"identity\": \n",
    "            return nn.Identity()\n",
    "        \n",
    "    def get_loss(self):\n",
    "        \n",
    "        \"\"\" \n",
    "            Method to select the loss function.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.loss_method == \"BCE\":\n",
    "            return nn.BCELoss()\n",
    "        \n",
    "        elif self.loss_method == \"L1\":\n",
    "            return nn.L1Loss()\n",
    "        \n",
    "        elif self.loss_method == \"MSE\":\n",
    "            return nn.MSELoss()\n",
    "\n",
    "        elif self.loss_method == \"CE\":\n",
    "            return nn.CrossEntropyLoss(weight = self.class_weights)\n",
    "\n",
    "        elif self.loss_method == \"BCEwLogit\":\n",
    "            if self.class_weights is not None:\n",
    "                pos_weight = torch.tensor([self.class_weights[1] / self.class_weights[0]])\n",
    "                return nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "            else: \n",
    "                return nn.BCEWithLogitsLoss()\n",
    "\n",
    "        elif self.loss_method == \"focal_loss\": \n",
    "            return FocalLoss(alpha=self.alpha, gamma=self.gamma)\n",
    "\n",
    "        elif self.loss_method == \"MFE\":\n",
    "            return MFELoss()\n",
    "\n",
    "        elif self.loss_method == \"MSFE\":\n",
    "            return MSFELoss()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"{self.loss_method} is not valid!\")\n",
    "    \n",
    "    def get_optimizer(self):\n",
    "        \"\"\" \n",
    "            Method to select the optimization method.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.opt_method == \"SGD\":\n",
    "            return torch.optim.SGD(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"Adam\":\n",
    "            return torch.optim.Adam(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"RMSprop\":\n",
    "            return torch.optim.RMSprop(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        else: \n",
    "            raise ValueError(f\"{self.opt_method} is not valid!\")\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader):\n",
    "        \"\"\" \n",
    "            Training phase of the NN.\n",
    "\n",
    "            Parameters: \n",
    "                train_loader (tensor) : Training data loader for training. \n",
    "                val_loader (tensor) : Validation data loader for validation.\n",
    "\n",
    "            Returns: \n",
    "                Returns the training and validation loss. \n",
    "        \"\"\"\n",
    "        loss_fn = self.get_loss()\n",
    "        optimizer = self.get_optimizer()        \n",
    "        size = len(train_loader.dataset)\n",
    "        t_loss=[]\n",
    "        val_loss = []\n",
    "        for e in range(self.epochs):\n",
    "            self.train()\n",
    "            train_loss = 0\n",
    "            for batch, (X, y) in enumerate(train_loader):\n",
    "                \n",
    "                y_logits = self(X).squeeze()\n",
    "                \n",
    "                loss = loss_fn(y_logits, y)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                train_loss += loss.item() * X.size(0)\n",
    "            train_loss_ = train_loss/len(train_loader.dataset) \n",
    "            t_loss.append(train_loss_)\n",
    "            \n",
    "            self.eval()\n",
    "            test_loss = 0\n",
    "            with torch.inference_mode():\n",
    "                for X, y in val_loader: \n",
    "                    \n",
    "                    y_logits = self(X).squeeze()\n",
    "                    test_loss += loss_fn(y_logits, y).item() * y.size(0)\n",
    "                \n",
    "        \n",
    "            test_loss_ = test_loss/len(val_loader.dataset)\n",
    "            val_loss.append(test_loss_)\n",
    "    \n",
    "        return t_loss, val_loss\n",
    "        \n",
    "            \n",
    "    def test_model(self, test_loader, loss_fn=None):\n",
    "        \"\"\" \n",
    "            A method for calcuating the test error.\n",
    "\n",
    "            Parameters: \n",
    "                test_loader (tensor) : Test data loader for reconstruction error. \n",
    "\n",
    "            Returns: \n",
    "                Returns the loss_per_sample and labels. \n",
    "        \"\"\"\n",
    "        loss_fn = self.get_loss()\n",
    "        test_loss = []\n",
    "\n",
    "        for e in range(self.epochs): \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    " \n",
    "                \n",
    "                test_loss_num = 0\n",
    "                for X, y in test_loader: \n",
    "                    y_logits = self(X).squeeze()\n",
    "                    test_loss_num += loss_fn(y_logits, y).item() * y.size(0)\n",
    "                    \n",
    "                test_loss_ = test_loss_num/len(test_loader.dataset)\n",
    "                test_loss.append(test_loss_)\n",
    "        return test_loss\n",
    "\n",
    "    def store(self, operation=None, path = None): #https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\n",
    "        \"\"\" \n",
    "            A method for storing or loading the model.\n",
    "\n",
    "            Parameters: \n",
    "                operation (str) : Name of the operation. \n",
    "                path (str) : Name of the path.\n",
    " \n",
    "        \"\"\"\n",
    "        if operation == \"save\": \n",
    "            torch.save(self.state_dict(), path)\n",
    "    \n",
    "        elif operation == \"load\": \n",
    "            self.load_state_dict(torch.load(path, weights_only = True))\n",
    "            print(\"Loading successfull ! \")\n",
    "\n",
    "    def analysis(self, l1, l2):\n",
    "        \"\"\" \n",
    "            Analysis of the Neural Network.\n",
    "\n",
    "            Parameters: \n",
    "                l1 (list) : List of loss in training.\n",
    "                l2 (list) : List of loss in validation.\n",
    "\n",
    "            Returns: \n",
    "                Returns graph that includes validation and training error. \n",
    "        \"\"\"\n",
    "        l1_arr = np.array(l1)\n",
    "        l2_arr = np.array(l2)\n",
    "\n",
    "        epoch_l = [i for i in range(1, self.epochs + 1)]\n",
    "        epoch_arr = np.array(epoch_l)\n",
    "\n",
    "        sns.lineplot(x = epoch_arr, y = l1_arr, label=\"Train Error\")\n",
    "        sns.lineplot(x = epoch_arr, y = l2_arr, label=\"Valid Error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, test):\n",
    "        \"\"\" \n",
    "            Prediction with NN.\n",
    "\n",
    "            Parameters: \n",
    "                test (tensor): Test loader for prediction. \n",
    "                \n",
    "\n",
    "            Returns: \n",
    "                Returns probabilities, predictions and labels. \n",
    "        \"\"\"\n",
    "        predictions=[]\n",
    "        labels = []\n",
    "        probs=[]\n",
    "        if self.loss_method == \"BCE\": \n",
    "            \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    \n",
    "                    output = self(X).squeeze()\n",
    "                    preds = (output > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(output)\n",
    "                    \n",
    "        elif self.loss_method == \"CE\": \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    output = self(X).squeeze()\n",
    "                    prob = torch.argmax(output, dim=1)\n",
    "                    preds = (prob>self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "                    \n",
    "        else:\n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    output = self(X).squeeze()\n",
    "                    prob = torch.sigmoid(output)\n",
    "                    preds = (prob > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "\n",
    "        all_preds = torch.cat(predictions).ravel()\n",
    "        all_labels = torch.cat(labels).ravel()\n",
    "        all_probs = torch.cat(probs).ravel()\n",
    "        \n",
    "        return all_probs, all_preds, all_labels\n",
    "        \n",
    "    def report(self, test, pred, labels): \n",
    "        \"\"\" \n",
    "            Reporting part for NN.\n",
    "\n",
    "            Parameters: \n",
    "                test (tensor): Test loader for prediction.\n",
    "                pred (tensor): Tensor for predictions.\n",
    "                labels (tensor): True labels.\n",
    "                \n",
    "\n",
    "            Returns: \n",
    "                Returns a confusion matrix. \n",
    "        \"\"\"\n",
    "        all_probs, all_preds, all_labels = self.predict(test)\n",
    "        all_probs_arr = all_probs.detach().numpy().ravel()\n",
    "        all_preds_arr = all_preds.detach().numpy().ravel()\n",
    "        all_labels_arr = all_labels.detach().numpy().ravel()\n",
    "        \n",
    "        cm = confusion_matrix(all_labels_arr, all_preds_arr)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.ylabel(\"Actual Class\")\n",
    "        plt.xlabel(\"Predicted Class\")\n",
    "\n",
    "        plt.show()\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a511c8a-0e25-4abc-9f01-fcebf4514baf",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d9624-c6af-4d9e-bda1-54fe07f5a323",
   "metadata": {},
   "source": [
    "1- Medium Data Scientists Diary. *Advanced guide to using nn modulelist in PyTorch*. Accessed April 10, 2025, from https://medium.com/data-scientists-diary/advanced-guide-to-using-nn-modulelist-in-pytorch-da4d49c109fc\n",
    "\n",
    "2- GeeksforGeeks. *How to implement neural networks in PyTorch*. Accessed on November 10, 2024, from https://www.geeksforgeeks.org/how-to-implement-neural-networks-in-pytorch/\n",
    "        \n",
    "3- Flock IO. *Credit Card Fraud Detection build your own model part 1*. Accessed March 12, 2025, from https://flock-io.medium.com/credit-card-fraud-detection-build-your-own-model-part-1-9b6cac3c991c\n",
    "    \n",
    "4- CodeSignal. *Making predictions with a trained PyTorch Model*. Accessed on April 29, 2025, from https://codesignal.com/learn/courses/building-a-neural-network-in-pytorch/lessons/making-predictions-with-a-trained-pytorch-model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
